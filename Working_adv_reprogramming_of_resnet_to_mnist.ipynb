{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Working adv reprogramming of resnet to mnist",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9WtipSzcGqvV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.models.resnet import resnet50\n",
        "\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pimg_size = (224,224) # resnet image size is 224,224 with 3 channels\n",
        "img_size = (28,28) # size of mnist images. mnist is gray scale so only 1 channel\n",
        "mask_size = pimg_size #size of masking matrix\n",
        "num_channels = 3 # num channels for resnet\n",
        "\n",
        "batch_size = 20 # larger batch sizes don't work cause i don't have enough cuda cores\n"
      ],
      "metadata": {
        "id": "Gpza5GARMVYV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad = int((pimg_size[0]-img_size[0])/2) # finding what padding I need on each border of the input image\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(padding = pad),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: torch.cat([x]*3)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# adding padding, normalizing the data, and using lambda to up the num of channels\n",
        "\n",
        "train_dataset = datasets.MNIST(root = 'data/', train=True, transform=transform, download=True) # download MNIST dataset\n",
        "\n",
        "test_dataset = datasets.MNIST(root = 'data/', train=False, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size, shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "MN3-54CdOJYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0') # using GPU\n",
        "model = resnet50(pretrained=True).to(device) # downloading pretrained framework\n",
        "model.eval() # puts the resnet model into evaluation mode which is good cause we don't want to change the model as this is an adversarial attack\n",
        "for param in model.parameters(): #making sure that no gradients are tracked while we use the model\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "g6VzgfLqONlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program = torch.rand(num_channels, *pimg_size, device=device, requires_grad = True) #creating our adversarial program starting point by making a random tensor, which we will adjust later\n",
        "\n",
        "\n",
        "pad = int((mask_size[0]-img_size[0])/2) \n",
        "\n",
        "mask = torch.zeros(num_channels, *img_size, device=device) # creating the mask\n",
        "mask = F.pad(mask, (pad,pad,pad,pad), value=1)\n",
        "\n",
        "optimizer = torch.optim.Adam([program], lr=0.05) #the optimizer which optimizes our adversarial program\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)  # used to adjust the learning rate as time goes on\n",
        "\n",
        "loss_criterion = nn.CrossEntropyLoss() # loss criterion\n",
        "\n",
        "\n",
        "num_classes = 10 # num classes for MNSIST"
      ],
      "metadata": {
        "id": "70wJj3ZEOwkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training loop\n",
        "num_epochs = 20\n",
        "steps_per_epoch = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    if epoch == 0:\n",
        "      print('Training has started')\n",
        "\n",
        "    lr_scheduler.step() # adjusting learning rate\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "      images = data[0].to(device) #grabbing images from the data\n",
        "      labels = data[1].to(device) #grabbing labels from the data\n",
        "\n",
        "      images = images + torch.tanh(program*mask) #additive contribution to the image\n",
        "\n",
        "      outputs = model(images) # see what resnet classifies\n",
        "      outputs = outputs[:,:num_classes] #only care about first 10 cause MNIST only has 10 classes.\n",
        "     \n",
        "      loss = loss_criterion(outputs, labels) # find loss\n",
        "      loss.backward() # backwards pass\n",
        "      optimizer.step() #update weights\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "\n",
        "      total_loss += loss.item() #calculate total loss\n",
        "      \n",
        "      if(i+1)%1500 == 0:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs},  Step {i+1}/{steps_per_epoch},  Loss:  {loss.item()},  Avg Loss for Epoch:  {total_loss/(i+1)}')\n",
        "\n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "-PVD7q6r-l9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "with torch.no_grad(): \n",
        "\n",
        "  total_loss = 0.0\n",
        "  total_steps = len(test_loader)\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "\n",
        "\n",
        "  for data in test_loader:\n",
        "      images = data[0].to(device)\n",
        "      labels = data[1].to(device) \n",
        "\n",
        "      images = images + torch.tanh(program*mask)\n",
        "      outputs = model(images)\n",
        "      outputs = outputs[:,:num_classes]\n",
        "\n",
        "      preds = torch.argmax(torch.softmax(outputs, dim =1), dim = 1) #grabs index of highest pred\n",
        "\n",
        "      total_correct += torch.sum(preds==labels).item() \n",
        "      total+= labels.shape[0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UgzI0y0EbKR8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = (total_correct/total) * 100.0\n",
        "print(f'Accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIX0F7PqwOV3",
        "outputId": "4f6d6b1a-b9a8-4adf-b5ad-ef6c0e11780f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.9600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({'program':program, 'mask':mask}, 'resnet50_adversarial.pth')"
      ],
      "metadata": {
        "id": "bRojqLKOO8UL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.load('resnet50_adversarial.pth')\n",
        "program = state['program']\n",
        "mask = state['mask']"
      ],
      "metadata": {
        "id": "z8FW5V4-PAJg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(program.detach().cpu())"
      ],
      "metadata": {
        "id": "GcIY7zyKPFfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = train_dataset[0]"
      ],
      "metadata": {
        "id": "8M4uYx0tPH5b"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(x)\n",
        "\n",
        "x.shape\n",
        "\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    return transforms.ToPILImage()(img.detach().cpu())"
      ],
      "metadata": {
        "id": "zyRh-lYgPMLF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(program)"
      ],
      "metadata": {
        "id": "OIpGg0EBPSB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VTRyoNe1F2sO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}