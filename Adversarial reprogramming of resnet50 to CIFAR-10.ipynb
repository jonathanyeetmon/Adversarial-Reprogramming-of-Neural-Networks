{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pimg_size = (224,224) # resnet image size is 224,224 with 3 channels\n",
    "img_size = (32,32) # size of Cifar 10 images. Also has 3 channels\n",
    "mask_size = pimg_size #size of masking matrix\n",
    "num_channels = 3 # num channels for resnet\n",
    "\n",
    "batch_size = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "pad = int((pimg_size[0]-img_size[0])/2) # finding what padding I need on each border of the input image\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(padding = pad),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# adding padding, normalizing the data, and using lambda to up the num of channels\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root = 'data/', train=True, transform=transform, download=True) # download  dataset\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root = 'data/', train=False, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') # using GPU\n",
    "model = resnet50(weights=True).to(device) # downloading pretrained framework\n",
    "model.eval() # puts the resnet model into evaluation mode which is good cause we don't want to change the model as this is an adversarial attack\n",
    "for param in model.parameters(): #making sure that no gradients are tracked while we use the model\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = torch.rand(num_channels, *pimg_size, device=device, requires_grad = True) #creating our adversarial program starting point by making a random tensor, which we will adjust later\n",
    "\n",
    "\n",
    "pad = int((mask_size[0]-img_size[0])/2) \n",
    "\n",
    "mask = torch.zeros(num_channels, *img_size, device=device) # creating the mask\n",
    "mask = F.pad(mask, (pad,pad,pad,pad), value=1)\n",
    "\n",
    "optimizer = torch.optim.Adam([program], lr=0.05) #the optimizer which optimizes our adversarial program\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2)  # used to adjust the learning rate as time goes on\n",
    "\n",
    "loss_criterion = nn.CrossEntropyLoss() # loss criterion\n",
    "\n",
    "\n",
    "num_classes = 10 # num classes for MNSIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started\n",
      "Epoch 1/20,  Step 1250/2500,  Loss:  1.5758728981018066,  Avg Loss for Epoch:  1.7716222479820252\n",
      "Epoch 1/20,  Step 2500/2500,  Loss:  1.5580806732177734,  Avg Loss for Epoch:  1.6559666161060334\n",
      "Epoch 2/20,  Step 1250/2500,  Loss:  1.3510596752166748,  Avg Loss for Epoch:  1.45336142244339\n",
      "Epoch 2/20,  Step 2500/2500,  Loss:  1.5012667179107666,  Avg Loss for Epoch:  1.4316902688026427\n",
      "Epoch 3/20,  Step 1250/2500,  Loss:  1.39601731300354,  Avg Loss for Epoch:  1.361149688768387\n",
      "Epoch 3/20,  Step 2500/2500,  Loss:  1.3686997890472412,  Avg Loss for Epoch:  1.361206523990631\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "num_epochs = 20\n",
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    if epoch == 0:\n",
    "      print('Training has started')\n",
    "\n",
    "    \n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "      images = data[0].to(device) #grabbing images from the data\n",
    "      labels = data[1].to(device) #grabbing labels from the data\n",
    "\n",
    "      images = images + torch.tanh(program*mask) #additive contribution to the image\n",
    "\n",
    "      outputs = model(images) # see what resnet classifies\n",
    "      outputs = outputs[:,:num_classes] #only care about first 10 cause MNIST only has 10 classes.\n",
    "     \n",
    "      loss = loss_criterion(outputs, labels) # find loss\n",
    "      loss.backward() # backwards pass\n",
    "      optimizer.step() #update weights\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "\n",
    "      total_loss += loss.item() #calculate total loss\n",
    "      \n",
    "      if(i+1)%(steps_per_epoch/2) == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs},  Step {i+1}/{steps_per_epoch},  Loss:  {loss.item()},  Avg Loss for Epoch:  {total_loss/(i+1)}')\n",
    "    lr_scheduler.step() # adjusting learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "with torch.no_grad(): \n",
    "\n",
    "  total_loss = 0.0\n",
    "  total_steps = len(test_loader)\n",
    "  total = 0\n",
    "  total_correct = 0\n",
    "\n",
    "\n",
    "  for data in test_loader:\n",
    "      images = data[0].to(device)\n",
    "      labels = data[1].to(device) \n",
    "\n",
    "      images = images + torch.tanh(program*mask)\n",
    "      outputs = model(images)\n",
    "      outputs = outputs[:,:num_classes]\n",
    "\n",
    "      preds = torch.argmax(torch.softmax(outputs, dim =1), dim = 1) #grabs index of highest pred\n",
    "\n",
    "      total_correct += torch.sum(preds==labels).item() \n",
    "      total+= labels.shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (total_correct/total) * 100.0\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'program':program, 'mask':mask}, 'resnet50_adversarial_CIFAR10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('resnet50_adversarial_CIFAR10.pth')\n",
    "program = state['program']\n",
    "mask = state['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(program.detach().cpu())\n",
    "x,y = train_dataset[0]\n",
    "\n",
    "\n",
    "torch.max(x)\n",
    "\n",
    "x.shape\n",
    "\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    return transforms.ToPILImage()(img.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(program)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7786879de3ca9dea9b7df161922c14e1f504e52c2047dafb43bdb8e22e64456a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
